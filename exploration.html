<!DOCTYPE HTML>
<!--
	Miniport by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>PH Twitter Fake News Analysis</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Nav -->
			<nav id="nav">
				<ul class="container">
					<li><a href="index.html#top">Top</a></li>
					<li><a href="index.html#overview">Overview</a></li>
					<li><a href="index.html#data">Data</a></li>
					<li><a href="exploration.html">Exploration</a></li>
					<li><a href="index.html#methods">Methods</a></li>
					<li><a href="index.html#results">Results</a></li>
					<li><a href="index.html#team">Team</a></li>
				</ul>
			</nav>

		<!-- Home -->
			<article id="top" class="wrapper style1">
				<div class="container">
					<div class="row">
						<div class="col-4 col-5-large col-12-medium">
							<span class="image fit"><img src="kkb_logo.png" alt="KKB48 logo" /></span>
						</div>
						<div class="col-8 col-7-large col-12-medium">
							<header>
								<h1><strong>KKB48</strong>'s Data Exploration.</h1>
							</header>
							<p>Before we model our data and analyse it to get the results, it is imperative to explore the raw data that we've collected in order to ensure that it is appropriate for data modelling and analysis. This has two segments: <strong>Preprocessing</strong> and <strong> Visualization </strong>. </p>

							<a href="https://colab.research.google.com/drive/1YSJOaV44jv4W4Z43tK24I6jRq182-WVU?usp=sharing#scrollTo=nVKKTAQarDEi" class="button large scrolly">Access our Data Exploration code here.</a>
							
						</div>
					</div>
				</div>
			</article>
			<script src="https://gist.github.com/KKB48/4a00882c18dc7b7b1e3aa9a009af1813.js"></script>
		
		<!-- Preprocessing -->
			<article id="overview" class="wrapper style2">
				<div class="container">
					<header>
						<h2>Preprocessing</h2>
					</header>
					<div class="row">
						<div class="col-12 col-6-medium col-12-small">
							<section class="box style3">
								<!-- <span class="icon featured fa-comments"></span> -->
								<h3>Loading Dataset</h3>
								<p>The data for this project was obtained by scraping tweets on Twitter posted from January 1, 2016 to December 31, 2022 with the keywords <b>"gabriela"</b> and <b>"npa”</b>.</p>
								
							</section>
						</div>
						<div class="col-12 col-6-medium col-12-small">
							<section class="box style3">
								<!-- <span class="icon solid featured fa-camera-retro"></span> -->
								<h3>Cleaning the Data</h3>
								<p>Mis/disinformation about the association of Gabriela Women's Party with the New People's Army can be correlated with the election of BBM-Sara in the executive branch.</p>
							</section>
						</div>
						<div class="col-12 col-6-medium col-12-small">
							<section class="box style3">
								<!-- <span class="icon featured fa-thumbs-up"></span> -->
								<h3>Ensuring Formatting Consistency</h3>
								<p>There are currently <i>956 rows</i> in the dataset but only 150 samples to work with for this project. The raw dataset contains <i>34 columns</i> provided by the scraper used in this project. Note that the columns were altered to have no spaces in between the words using the <code>deleteSpaces</code> function and the <code>rename</code> function. <br> We continue cleaning the dataset by extracting the data from relevant columns</p>
								<p>Then, we check the dataset if there are any empty rows by checking the tail-end of the dataset using <code>tail</code>. In our dataset, we can see that there are indeed empty rows.</p>
								<p>Since there are empty rows in our dataset, we drop these rows using the <code>dropna</code> function.</p>
								<p>After this, the dataset is left with <i>150 rows and 13 columns</i>, which we were able to determine using the <code>shape</code> function. <br> The relevant columns in our dataset are as follows:</p>
								<ol type="1">
									<li><b>AccountHandle</b> - username of the account</li>
									<li><b>AccountType</b> - may only be anonymous, identified, and media</li>
									<li><b>Joined</b> - date at which the Twitter account was created</li>
									<li><b>Following</b> - number of users followed by the account</li>
									<li><b>Followers</b> - number of followers of the account</li>
									<li><b>Tweet</b> - any message posted to Twitter which may contain photos, videos, links, and text</li>
									<li><b>TweetType</b> - may be any combination of Text, Image, URL, and Reply</li>
									<li><b>DatePosted</b> - date at which the tweet was posted which would only be from January 1, 2016 to December 31, 2022</li>
									<li><b>ContentType</b>: may only be Emotional, Rational, and Transactional</li>
									<li><b>Likes</b> - number of likes obtained by the tweet</li>
									<li><b>Replies</b> - number of replies obtained by the tweet</li>
									<li><b>Retweets</b> -number of retweets obtained by the tweet</li>
									<li><b>QuoteTweets</b> - number of quote tweets obtained by the tweet</li>
								</ol>
 
 								<p>The types of data present from this dataset are the following:</p>
									
								<ul>
									<li><b>Categorical (Qualitative)</b>: AccountHandle, AccountType, Tweet, TweetType, ContentType</li>
									<li><b>Numerical (Quantitative)</b>: Following, Followers, Likes, Replies, Retweets, QuoteTweets</li>
									<li><b>Date</b>: DatePosted, Joined</li>
								</ul>
							</section>
						</div>
						<div class="col-12 col-6-medium col-12-small">
							<section class="box style3">
								<!-- <span class="icon featured fa-thumbs-up"></span> -->
								<h3>Checking for Missing Values</h3>
								<p>We checked for columns with either missing, <code>None</code>, or <code>numpy.NaN</code> values in the data frame columns using the <code>.isna().any()</code> function. From here, we can see the columns from the dataset in which we need to handle missing values if there are any. If none, (i.e. the <code>isna()</code> function will return nothing) then we proceed with transforming the data. <br>From our dataset, we can see that there are no columns with any missing values.</p>
							</section>
						</div>
						<div class="col-12 col-6-medium col-12-small">
							<section class="box style3">
								<!-- <span class="icon featured fa-thumbs-up"></span> -->
								<h3>Transforming Data</h3>
								<p>Given the three categories of features within the data set (categorical, numerical, and date), we transformed the data within the categories to similar data type in order to remain consistency and ensure uniformity of data types across the dataset. For categorical values, we changed the data into a <b>string (str)</b> datatype while numerical values are transformed into <b>64-bit signed integer</b> data type.  <br>Meanwhile for the data category, the Joined column uses the <code>to_period(’m’)</code> function in order to cast the datetimelike value and cast it to index at a monthly frequency. On the other hand, the DatePosted column will be transformed to use the default datetime format which is <code>YYYY-MM-DD HH:MM:SS</code>.</p>
							</section>
						</div>
						<div class="col-12 col-6-medium col-12-small">
							<section class="box style3">
								<!-- <span class="icon featured fa-thumbs-up"></span> -->
								<h3>Categorical Encoding</h3>
								<p>To simplify the categorical features in the dataset, we employ categorical encoding for the AccountType, ContentType, and TweetType features. Thus, we encoded these features into their respective numerical values.<br>For <b>AccountType</b>, the encoding was: </p>
								<ul>
									<li>0 for “Anonymous”</li>
									<li>for “Identified”</li>
									<li>for “Media”</li>
								</ul>
								<p>and the encoded value was saved as <code>Temp_AccountType</code> feature in the <code>df</code> dataset.<br>For <b>ContentType</b>, the encoding was:</p>
								<ul>
									<li>0 for “Emotional”</li>
									<li>1 for “Rational”, and</li>
									<li>2 for “Transactional”</li>
								<ul>
								<p>and the encoded value is saved as <code>Temp_ContentType</code> feature in the <code>df</code> dataset.</p>
								<p>For the TweetType, we split the string of the feature to tokenize the content of the column into a list. Then, we mapped the list of tokens of the TweetType column via <i>one hot encoding</i> to see if the tweet contains certain tweet_types (Text, Image, URL, and Reply) by putting a value of 1 to their respective feature under the <code>df</code> dataset.</p>
							</section>
						</div
						<div class="col-12 col-6-medium col-12-small">
							<section class="box style3">
								<!-- <span class="icon featured fa-thumbs-up"></span> -->
								<h3>Normalization</h3>
								<p>In order to ensure uniformity in how data looks, reads, and can be utilized for machine learning modeling (ML modeling), we normalized the features with numerical values as described in the <code>feat_num</code> of df dataset. We used the <code>MinMaxScaler()</code> function of preprocessing module from sklearn to scale the features from the interval <i>[0,1]</i>. We first fit the scaler using the <code>fit()</code> function to estimate the minimum and maximum observable values. Then, we normalized the data using the <code>transform()</code> function. The normalized data is now stored in <b>df_scaled</b>.</p>
							</section>
						</div	
						
					</div>
				</div>
			</article>
		
		<!-- Time Series -->
			<article id="overview" class="wrapper style3">
				<div class="container">
					<header>
						<h2>Time Series Analysis</h2>
					</header>
					<div class="row">
						<div class="col-12 col-6-medium col-12-small">
							<article class="box style3">
								<h3>Binning Date Features</h3>
								<p> In order to organize the continuous date and time data, it was divided into either <b>Monthly</b> or <b>Yearly</b> bins or intervals. 
								<br> For the <b>DatePosted</b> Feature, the datetime data type is converted into periods using the <code>to_period(’m’)</code> function. Hence, the DatePosted feature now contains the month when the tweet was posted. Then, the column was divided into monthly interval bins by using <code>post_bins = pd.period_range(post_start, post_end, freq='M')</code> where <code>post_start</code> is the earliest DatePosted month into the dataset while the <code>post_end</code> is the latest and the <code>freq</code> or frequency is set to <b>‘M’</b> or <b>monthly</b>. Thus, the post_bins contains the binning of the DatePosted feature returned by the period_range function which returns a fixed monthly frequency PeriodIndex.
								<br>The JoinedDate feature is converted into yearly interval using the `PeriodIndex(df[’Joined’]).year`. Thus, the added temporary feature in the dataset **Temp_YearJoined** now contains the year when the account was created in twitter.</p>
							</article>
						</div>
						
						<div class="col-12 col-6-medium col-12-small">
							<article class="box style3">
								<h3>Interpolation</h3>
								<p>To aggregate and interpolate the data, we first created an empty df dataset named `df_time_series` in which the features and rows are characterized with:</p>
								<ul>
									<li>First feature is the total count of tweets per time bin</li>
									<li>The succeeding features are each type of content and account separated by each column, and </li>
									<li>The rows are the indices of the time binning with monthly frequency </li>
								</ul>
  								<p>Then, the `count_time_series` function counts the number of tweets for each column depending on the content of the tweet and account type of the user of the tweet. Note that there will be null values in `df_time_series` since the values of the columns in `df_time_series` will only increase if it is encountered in the dataset.
								<br>Then, we interpolated the `df_time_series` using the interpolate function with <b>linear</b> method. Moreover, in order to remove the leading NaN values in the dataset, we filled the values with 0 using `fillna(0)` method.</p>
							</article>
						</div>

					</div>
				</div>
			</article>
							
		
		<!-- NLP -->
			<article id="overview" class="wrapper style3">
				<div class="container">
					<header>
						<h2>Natural Language Processing</h2>
						<p>In order to obtain a proper analysis of the tweets in our dataset, the removal of stop words, links, mentions, hashtags, and some punctuations in the tweets were performed on the contents of each tweet.
						<br>These removals are necessary in order to keep the focus on key points of the tweets.</p>
					</header>
					<div class="row">
						<div class="col-12 col-6-medium col-12-small">
							<article class="box style3">
								<p>After removing the unnecessary parts of the tweets, we proceed with obtaining the top 10 most frequent words used in the tweets.</p>
							</article>
						</div>
					</div>
				</div>
			</article>
							
			
			<!-- Visualization -->
			<article id="overview" class="wrapper style3">
				<div class="container">
					<header>
						<h2>Visualization</h2>
						<p>In order to gain deeper insights from the dataset that we have, we created multiple visualizations that helped us to better understand the underlying patterns and trends that were not immediately apparent from the raw data.
						<br>To break down the distribution of tweets with disinformation based on account type and content type, we made pie charts that display the overall percentage of tweets for each account type and content type.
						<br>From the pie chart on the left we can see that anonymous users post the most amount of tweets containing mis/disinformation about the topic.
						<br>Meanwhile, the pie chart on the right shows how tweets containing mis/disinformation are split evenly between having rational and emotional content.</p>
					</header>
					<div class="row">
						<div class="col-12 col-6-medium col-12-small">
							<article class="box style3">
								<iframe src="assets\graphs\1_pie_account_content_types.html" scrolling="no" style="border:none;" seamless="seamless" height="525" width="100%"></iframe>
								<p>To analyze the content type of the tweets made by the different types of accounts, we created a bar graph that shows the most frequent content type among the different account types.
								<br>For tweets posted by anonymous accounts, we can see how the there is no apparent significant difference between the number of tweets containing rational and emotional content.
								<br>For tweets posted by identified accounts, we can see that there are more tweets that contain emotional content.
								<br>For tweets posted by media accounts, we can see that there are only tweets that contain rational content.</p>
								
								<iframe src="assets\graphs\2_bar_account_content_type_distribution.html" scrolling="no" style="border:none;" seamless="seamless" height="525" width="100%"></iframe>
								<p>To analyze the time posted for the tweets, we created a bar graph that shows the most frequent month that the tweets were posted by the users.
								<br>Here, we can see that October was the most frequent month that the tweets were posted by the users.</p>
								
								<iframe src="assets\graphs\3_bar_tweet_frequency_by_month_posted.html" scrolling="no" style="border:none;" seamless="seamless" height="525" width="100%"></iframe>
								<p>To analyze the time at which different accounts post tweets, we created a line plot that shows the most frequent month in which each account type posted their tweets.
								<br>Here, we can see that for all account types, October is the most frequent month in which the tweets were posted.</p>
								
								<iframe src="assets\graphs\4_line_tweet_frequency_per_account_type_by_month_posted.html" scrolling="no" style="border:none;" seamless="seamless" height="525" width="100%"></iframe>
								<p>To analyze the time at which tweets with different content types were posted, we created a line plot that shows the most frequent month in which tweets with each content type were posted.
								<br>Here, we can see that for both content types, October is the most frequent month in which tweets were posted.</p>
								
								<iframe src="assets\graphs\5_line_tweet_frequency_per_content_type_by_month_posted.html" scrolling="no" style="border:none;" seamless="seamless" height="525" width="100%"></iframe>
								<p>To analyze the time at which the accounts were created, we made a bar graph that shows the most frequent year in which the accounts were created.
								<br>Here, we can see that 2020 was the most frequent year in which the accounts were created.</p>
								
								<iframe src="assets\graphs\6_bar_tweet_frequency_by_year_joined.html" scrolling="no" style="border:none;" seamless="seamless" height="525" width="100%"></iframe>
								<p>To analyze the time at which different types of accounts were created, we made a bar graph that shows the most frequent year in which each account type was created.
								<br>Here, we can see that 2020 was the most frequent year in which the accounts were created, wherein anonymous accounts were the most frequent type of account created.</p>
								
								<iframe src="assets\graphs\7_bar_tweet_frequency_per_account_type_by_year_joined.html" scrolling="no" style="border:none;" seamless="seamless" height="525" width="100%"></iframe>
								<p>To analyze the comparison between the time in which the tweets were posted and the time in which their respective accounts were created, we created a heatmap to determine the most frequent pairing of month the tweet was posted and the year when the account was created.
								<br>Here, we can see that the column of the year 2020 contains a good number of the saturated cells as well as the most saturated cell, wherein the most saturated cell is the pairing of October time of posting and 2020 year of creation.</p>

								<iframe src="assets\graphs\8_heatmap_tweet_frequency_by_month_posted_vs_year_joined.html" scrolling="no" style="border:none;" seamless="seamless" height="525" width="100%"></iframe>
							</article>
						</div>
					</div>
				</div>
			</article>
		
		

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
